{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# HSE Summer School NLP&DA\n",
    "\n",
    "![](https://www.hse.ru/data/2014/06/25/1309038576/logo_hse_cmyk_e.jpg)\n",
    "\n",
    "Учебный проект по теме \"Тональность отношений субъектов (именованных сущностей)\", предполагающий разработку участниками школы под руководством тьюторов программных средств, решающих задачу определения мнения сторон о различных событиях, освещаемых в новостях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужен алгоритм, который по выделенным сущностям может найти пары этих сущностей в тексте и вырезать соответствующие куски между ними + несколько слов справа-слева. Возможно, имеет смысл идти от N-ой выделенной сущности до N+2, и включать всё до неё. \n",
    "\n",
    "Чем может помочь синтаксический анализ?\n",
    "\n",
    "Чем поможет морфологический анализ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/Users/dmitrys/anaconda2/lib/python2.7/site-packages/\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymorphy2\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "import string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     5,
     31,
     49,
     77
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadAnswer(number):\n",
    "    with open(\"Texts/art{}.opin.txt\".format(number)) as f:\n",
    "        d = f.read()\n",
    "    return d\n",
    "\n",
    "def loadText(number):\n",
    "    with open(\"Texts/art{}.txt\".format(number)) as f:\n",
    "        d = f.read()\n",
    "    return d\n",
    "\n",
    "def transformAnnotation(number):\n",
    "    \"\"\"\n",
    "    Given number loads txt file with annotation \n",
    "    Returns DataFrame with transformed annotation\n",
    "    \"\"\"\n",
    "    with open(\"Texts/art{}.ann\".format(number)) as f:\n",
    "        d = f.read()\n",
    "\n",
    "    d = d.split(\"\\n\")\n",
    "\n",
    "    for i in range(len(d)):\n",
    "        d[i] = d[i].split(\"\\t\")\n",
    "\n",
    "    d = pd.DataFrame(d)\n",
    "    d.drop([0], axis=1, inplace=True)\n",
    "    d = pd.concat([d, pd.DataFrame(d[1].apply(lambda x: x.split()).tolist())], axis=1)\n",
    "    d.columns = [\"to_delete\", \"entity\", \"entity_car\", \"pos_1\", \"pos_2\"]\n",
    "    d.drop([\"to_delete\"], axis=1, inplace=True)\n",
    "    d[\"entity\"] = d[\"entity\"].apply(lambda x: x.strip(\"\\r\"))\n",
    "    d[\"entity\"] = d[\"entity\"].apply(lambda x: x.decode(\"utf8\"))\n",
    "    \n",
    "    return d\n",
    "\n",
    "def transformAnswer(number):\n",
    "    \"\"\"\n",
    "    Given number loads txt file with answer \n",
    "    Returns DataFrame with transformed answer\n",
    "    \"\"\"\n",
    "    answ = loadAnswer(number)\n",
    "    answ = answ.split(\"\\n\")\n",
    "\n",
    "    for i in range(len(answ)):\n",
    "        answ[i] = answ[i].split(\",\")\n",
    "\n",
    "    answ = pd.DataFrame(answ)\n",
    "    answ.columns = [\"entity_1\", \"entity_2\", \"attitude\", \"time\"]\n",
    "    answ.dropna(inplace=True)\n",
    "    answ.time = answ.time.apply(lambda x: x.strip(\"\\r\"))\n",
    "    \n",
    "    return answ\n",
    "\n",
    "def loadRuSentiLex():\n",
    "    \"\"\"\n",
    "    Loads the RuSentiLex 2017 dictionary\n",
    "    Returns data frame with [\"word\", \"tag\", \"word_lemmatized\", \"tone\", \"certainty\"]\n",
    "    \"\"\"\n",
    "    with open(\"RuSentiLex2017_revised_2.txt\") as f:\n",
    "        Rusentilex = f.read().decode(\"cp1251\").encode(\"utf8\")\n",
    "        Rusentilex = Rusentilex[1510:]\n",
    "\n",
    "    Rusentilex = Rusentilex.split(\"\\n\")\n",
    "    for i, item in enumerate(Rusentilex):\n",
    "        Rusentilex[i] = item.split(\",\")\n",
    "\n",
    "    for i in Rusentilex:\n",
    "        if len(i) < 5:\n",
    "            Rusentilex.remove(i)\n",
    "\n",
    "    Rusentilex = pd.DataFrame(Rusentilex)\n",
    "    Rusentilex.drop([5, 6, 7], axis=1, inplace=True)\n",
    "    Rusentilex.columns = [\"word\", \"tag\", \"word_lemmatized\", \"tone\", \"certainty\"]\n",
    "    Rusentilex[\"certainty\"] = Rusentilex[\"certainty\"].apply(lambda x: x.strip('\\r'))\n",
    "    \n",
    "    \n",
    "    Rusentilex[\"tone\"] = Rusentilex[\"tone\"].apply(lambda x: x.strip(' '))\n",
    "    Rusentilex[\"certainty\"] = Rusentilex[\"certainty\"].apply(lambda x: x.strip(' '))\n",
    "    \n",
    "    return Rusentilex\n",
    "\n",
    "def cleanString(myString):\n",
    "    return myString.translate(None, string.punctuation).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![](http://cathyreisenwitz.com/wp-content/uploads/2016/01/no.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Словарь РуСентиЛекс\n",
    "\n",
    "Структура: \n",
    "- 1 слово или словосочетание,\n",
    "- 2 Часть речи или синтаксический тип группы,\n",
    "- 3 слово или словосочетание в лемматизированной форме, \n",
    "- 4 Тональность: позитивная (positive), негативная(negative), нейтральная (neutral) или неопределеная оценка, зависит от контекста (positive/negative),\n",
    "- 5 Источник: оценка (opinion), чувство (feeling), факт (fact),\n",
    "- 6 Если тональность отличается для разных значений многозначного слова, то перечисляются все значения слова по тезаурусу РуТез и дается отсылка на сооветствующее понятие - имя понятия в кавычках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rusentilex = loadRuSentiLex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>word_lemmatized</th>\n",
       "      <th>tone</th>\n",
       "      <th>certainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>аборт</td>\n",
       "      <td>Noun</td>\n",
       "      <td>аборт</td>\n",
       "      <td>negative</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>абортивный</td>\n",
       "      <td>Adj</td>\n",
       "      <td>абортивный</td>\n",
       "      <td>negative</td>\n",
       "      <td>fact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>абракадабра</td>\n",
       "      <td>Noun</td>\n",
       "      <td>абракадабра</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>абсурд</td>\n",
       "      <td>Noun</td>\n",
       "      <td>абсурд</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>абсурдность</td>\n",
       "      <td>Noun</td>\n",
       "      <td>абсурдность</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    tag word_lemmatized      tone certainty\n",
       "0        аборт   Noun           аборт  negative      fact\n",
       "1   абортивный    Adj      абортивный  negative      fact\n",
       "2  абракадабра   Noun     абракадабра  negative   opinion\n",
       "3       абсурд   Noun          абсурд  negative   opinion\n",
       "4  абсурдность   Noun     абсурдность  negative   opinion"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rusentilex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opinion             9269\n",
       "fact                5297\n",
       "feeling             1536\n",
       "operator              41\n",
       "negative               2\n",
       "positive               2\n",
       "fact В ТЕЗ empty       1\n",
       "fact В ТЕЗ EMPTY       1\n",
       "opinegativenion        1\n",
       "Name: certainty, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rusentilex.certainty.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSentimentCertainity(word):\n",
    "    tone, certainty =  Rusentilex[[\"tone\", \"certainty\"]][Rusentilex.word.isin([word])].values[0]\n",
    "    return tone, certainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('negative', 'fact')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSentimentCertainity(\"аборт\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "entities = transformAnnotation(1)\n",
    "a = transformAnswer(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# надо идти по всем сущностям с правилами остановки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = loadText(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Author, Unknown} \r\n",
      "\n",
      "{Author, Unknown} СМИ Ирана: Финляндия не хочет вступать в НАТО из страха перед Россией?\r\n",
      "\n",
      "{Author, Unknown} inosmi.ru\r\n",
      "\n",
      "{Author, Unknown} 5-го, 2016\r\n",
      "\r\n",
      "\n",
      "{Author, Unknown} Зачем американцам понадобилось перебросить 250 своих военных на северо-восток Сирии, к окрестностям города Румийлан, разбирался обозреватель Khorasan (\n",
      "{Author, Unknown} 30.04) Алиреза Резахах (Alireza Rezakhah). \n",
      "{Author, Unknown} Согласно заявлениям из Пентагона, цель США — способствовать освобождению от боевиков ИГИЛ стратегически важного города Ракка. \n",
      "{Author, Unknown} Однако в Дамаске действия Вашингтона резко осудили и назвали покушением на территориальный суверенитет Сирии. \n",
      "{Author, Unknown} Примерно в аналогичном ключе высказалась и Москва, где «несогласованные с Дамаском» шаги Белого дома назвали фактором, вызывающим озабоченность.\r\n",
      "\r\n",
      "\n",
      "{Author, Unknown} Почему же и в Москве и Дамаске, которые также ведут борьбу прот\n"
     ]
    }
   ],
   "source": [
    "print(t[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'nomn'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = morph.parse(u\"аборт\")[0]\n",
    "p.tag.case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>entity_car</th>\n",
       "      <th>pos_1</th>\n",
       "      <th>pos_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>СМИ</td>\n",
       "      <td>ORG</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ирана</td>\n",
       "      <td>LOC</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Финляндия</td>\n",
       "      <td>GEOPOLIT</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>НАТО</td>\n",
       "      <td>ORG</td>\n",
       "      <td>80</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Россией</td>\n",
       "      <td>GEOPOLIT</td>\n",
       "      <td>101</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ru</td>\n",
       "      <td>ORG</td>\n",
       "      <td>137</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Сирии</td>\n",
       "      <td>LOC</td>\n",
       "      <td>271</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Румийлан</td>\n",
       "      <td>LOC</td>\n",
       "      <td>300</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Khorasan</td>\n",
       "      <td>ORG</td>\n",
       "      <td>334</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Алиреза Резахах (Alireza Rezakhah</td>\n",
       "      <td>PER</td>\n",
       "      <td>370</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               entity entity_car pos_1 pos_2\n",
       "4                                 СМИ        ORG    39    42\n",
       "5                               Ирана        LOC    43    48\n",
       "6                           Финляндия   GEOPOLIT    50    59\n",
       "7                                НАТО        ORG    80    84\n",
       "8                             Россией   GEOPOLIT   101   108\n",
       "11                                 ru        ORG   137   139\n",
       "16                              Сирии        LOC   271   276\n",
       "17                           Румийлан        LOC   300   308\n",
       "18                           Khorasan        ORG   334   342\n",
       "21  Алиреза Резахах (Alireza Rezakhah        PER   370   403"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities[~entities.entity.isin([\"Unknown\", \"Author\"])].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def Text_to_dict(number):\n",
    "    t = loadText(number)\n",
    "    text_dict = t.split(\"\\n\\n\")\n",
    "    text_dict = {i:parag for i, parag in enumerate(text_dict)}\n",
    "    sentence_dict = {i:{} for i in range(len(text_dict))}\n",
    "\n",
    "    for key, paragraph in text_dict.iteritems():\n",
    "        paragraph = paragraph.split(\"{Author, Unknown}\")\n",
    "        for sent_numbet, sentence in enumerate(paragraph):\n",
    "\n",
    "            sentence = cleanString(sentence)\n",
    "            if len(sentence) != 0:\n",
    "                sentence_dict[key][sent_numbet] = sentence\n",
    "                #tknzr.tokenize()\n",
    "    return sentence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for key, value in t.iteritems():\n",
    "#     print(\"paragraph number\", key)\n",
    "#     for another_key, another_value in value.iteritems():\n",
    "        \n",
    "#         print(\"sentence_number\", another_key)\n",
    "#         for word in another_value:\n",
    "#             print word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text = Text_to_dict(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = entities[~entities.entity.isin([\"Unknown\", \"Author\"])].entity.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getEntityPositions(text, entities):\n",
    "    ENTITIES = pd.DataFrame(columns=[\"entity\", \"paragraph\", \"sentence\", \"loc_start\", \"loc_end\"])\n",
    "    \n",
    "    for paragraph in text:\n",
    "        for sentence in text[paragraph]:\n",
    "            #for word in text[paragraph][sentence]:\n",
    "            for entity in list(entities):\n",
    "                if entity in text[paragraph][sentence]:\n",
    "                    \n",
    "                    loc_start = text[paragraph][sentence].find(entity)\n",
    "                    loc_end = loc_start + len(entity)\n",
    "                    \n",
    "                    to_append =   {\"entity\":entity, \n",
    "                                   \"paragraph\":paragraph, \n",
    "                                   \"sentence\":sentence,\n",
    "                                   \"loc_start\":loc_start,\n",
    "                                   \"loc_end\":loc_end}\n",
    "                    \n",
    "                    ENTITIES = ENTITIES.append(to_append, ignore_index = True)\n",
    "    return ENTITIES.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ENTITIES = getEntityPositions(text, entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ENTITIES.entity.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Алиреза Резахах (Alireza Rezakhah\n",
      "Аль-Джазира\n",
      "Али Алеми (Ali Alemi\n",
      "Хоссаму Аль-Саеду\n",
      "премьер-министр Италии\n"
     ]
    }
   ],
   "source": [
    "for entity in entities.unique():\n",
    "    if entity not in ENTITIES.entity.unique():\n",
    "        print entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          СМИ\n",
       "1        Ирана\n",
       "2    Финляндия\n",
       "3         НАТО\n",
       "4      Россией\n",
       "Name: entity, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence</th>\n",
       "      <th>loc_start</th>\n",
       "      <th>loc_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>СМИ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ирана</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Финляндия</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>НАТО</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Россией</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity paragraph sentence loc_start loc_end\n",
       "0        СМИ         1        1         1       4\n",
       "1      Ирана         1        1         5      10\n",
       "2  Финляндия         1        1        11      20\n",
       "3       НАТО         1        1        41      45\n",
       "4    Россией         1        1        62      69"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENTITIES.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     3
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Author,\n",
      "Unknown}\n",
      "{Author,\n",
      "Unknown}\n",
      "россия\n",
      "и\n",
      "кратковременный\n",
      "успех\n",
      "в\n",
      "сирия\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(lemmatize(t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
